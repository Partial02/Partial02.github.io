---
layout: single
title: "[범주형 자료분석 2주차] 다항 분포와 최대우도 추정"
categories: Statistics
tag: [STAT, STAT343]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    th, td {
        text-align: center;
    }
    .r {
        color: red;
    }
</style>

## Mar 10 (Mon)

이전 시간에 배웠던 다항 분포에서 시작한다

### Multinomial Distribution

다항 분포의 꼴은 기억날 것이다

$$P(Y_1=y_1,\dots,Y_c=y_c)=\frac{n!}{y_1!\cdots y_c!}\pi_1^{y_1}\cdots \pi_c^{y_c}$$

다항 분포의 j번째 클래스에 속하는 관측치의 개수를 Y_j라 할 때, 평균과 분산은 각각 1차 중심적률과 2차 중심적률을 활용하여 증명된다. 전사건의 확률이 1이라는 것을 적극 활용하면 적률을 구할 수 있다. 그러니 공분산을 구하는 과정만 기록해두겠다. 나머진 필기를 참조하자.

#### 다항 분포의 공분산 (전사건의 확률은 1)

i, j번째 클래스에 속하는 관측치의 개수를 각각 Y_i, Y_j라 하자. 공분산의 정의에 따라

$$Cov(Y_i, Y_j)=E[Y_iY_j]-E[Y_i]E[Y_j]$$

이다. 다항 분포의 평균은 알고 있으므로, 첫 항만 계산하면 된다. 기댓값의 정의에 따라

$$E[Y_iY_j]=\sum_{y_i=0}^n\sum_{y_j=0}^ny_iy_j\frac{n!}{y_1!\cdots y_c!}\pi_1^{y_1}\cdots \pi_c^{y_c}$$

에서 y_i와 y_j가 0일 때는 전체 식에 0이 곱해져 결과도 0이 되므로 각각이 0인 케이스는 시그마에서 제외한다.

$$E[Y_iY_j]=\sum_{y_i=1}^n\sum_{y_j=1}^ny_iy_j\frac{n!}{y_1!\cdots y_c!}\pi_1^{y_1}\cdots \pi_c^{y_c}$$

이제 y_i와 y_j를 분모의 팩토리얼과 각각 약분한뒤, 시그마의 밑을 변환하여 전사건의 확률분포를 만들자.

$$E[Y_iY_j]=\sum_{y_i^*=0}^{n-1}\sum_{y_j^*=0}^{n-1}\frac{n!}{y_1!\cdots y_i^*!\cdots y_j^*!\cdots y_c!}\pi_1^{y_1}\cdots \pi_i^{y_i^*}\cdots \pi_j^{y_j^*}\cdots \pi_c^{y_c}(\pi_i\pi_j)$$

그런데 이중 시그마 내부의 식을 잘 살펴보면 Y_i * Y_j의 결합확률분포함수(joint pdf)이다. 따라서

$$\begin{align} E[Y_iY_j]&=\sum_{y_i^*=0}^{n-1}\sum_{y_j^*=0}^{n-1}\frac{n!}{y_1!\cdots y_i^*!\cdots y_j^*!\cdots y_c!}\pi_1^{y_1}\cdots \pi_i^{y_i^*}\cdots \pi_j^{y_j^*}\cdots \pi_c^{y_c}(\pi_i\pi_j)\\&=n(n-1)\pi_i\pi_j\sum_{y_i^*=0}^{n-1}\sum_{y_j^*=0}^{n-1}\frac{n!}{y_1!\cdots y_i^*!\cdots y_j^*!\cdots y_c!}\pi_1^{y_1}\cdots \pi_i^{y_i^*}\cdots \pi_j^{y_j^*}\cdots \pi_c^{y_c}\\&=n(n-1)\pi_i\pi_j\sum_{y_i^*=0}^{n-1}\sum_{y_j^*=0}^{n-1}P(\cdots,Y_i=y_i^*,Y_j=y_j^*,\cdots|n-2)\\&=n(n-1)\pi_i\pi_j \end{align}$$

여기서 이해가 안됐던 부분이 있어서 기록해둔다.

Y_i * Y_j가 0이 아니기 위해선 i 클래스와 j 클래스에 속하는 원소가 각각 하나씩은 들어가 있어야한다. 즉 이제 할당되지 않은 관측치의 개수는 n-2개인 것. 따라서 아무리 시그마의 위끝이 n-1이라고 해도, <strong>y_i star나 y_j star가 n-1인 경우의 수는 이미 제외된 상태</strong>다. 두 시그마의 위끝이 n-1인데 왜 joint pdf는 n-2인지 헷갈렸어서 특기해둔다.

그래서 구하려는 공분산은 정의에 따라

$$\begin{align} Cov(Y_i, Y_j)&=E[Y_iY_j]-E[Y_i]E[Y_j]\\&=n(n-1)\pi_i\pi_j-n^2\pi_i\pi_j\\&=-n\pi_i\pi_j \end{align}$$

공분산이 음수인 이유는 다항 분포에선 <strong class="r">Y_i의 개수가 증가하면 자연스레 Y_j의 개수는 감소하는 경향을 갖기 때문</strong>이다. 당연한 일이다. 전체 관측치의 개수는 n으로 고정이니까

### Likelihood Function & MLE

이제 우도 함수 $$l(\pi)$$로 들어가보자. 우도 함수를 정의할 때 가장 중요한 지점은 확률질량함수(pmf)에서는 parameter가 주어진(given) 상태로 확률변수에 대한 함수를 작성하는 반면(데이터 관점), <strong class="r">우도함수에서는 data가 given이고 parameter에 대한 함수</strong>로 정의된다는 것이다.(모수 추정 관점)

즉 data가 given돼있다는 것은 <strong class="r">data를 관측하기 전에는 MLE를 알 수 없다</strong>는 것이다. 여기서 given은 고정(fixed)됐다는 것으로, 우도는 parameter에 대한 함수이기에 sample data가 존재하지 않으면 추정할 기반이 없게된다. 이점을 유의하자.

이 우도함수를 기반으로, 가장 높은 발생 확률을 갖는 파라미터를 최대우도추정량(MLE; Maximum Likelihood Estimator)이라고 하고 $$\hat\pi^{\text{MLE}}$$라고 표기한다. hat은 추정량이라는 뜻이다.

예를 들어 이항 분포에서 우도함수는 pmf와 같은 식을 공유하지만 각자 포커스가 다르다. 이항 분포의 우도 함수는

$$L(\pi;y)=\frac{n!}{y!(n-y)!}\pi^y(1-\pi)^{1-y}$$

이다. 그런데 직관적으로 생각을 해보자. 표본 n번 중 성공이 y번 나왔다. 그렇다면 실제 성공확률(parameter)는 얼마일까? 상식적으로 n/y이지 않을까? 증명은 필기본을 참고하자.

여기서 첫번째 포인트는 <strong class="r">일단 모수 pi가 0이나 1인 경우는 빼고 계산</strong>한다는 것이다. 위의 우도함수를 편하게 미분하기 위해서는 log를 씌워 로그 우도함수 꼴로 미분을 해야하는데, 여기서 pi가 0이나 1이 되어버리면 로그 자체가 정의가 안되게 된다. 즉 <strong class="r">로그 우도함수가 발산</strong>하면서 미분 과정이 깨지기 때문에 양끝의 케이스는 빼고 생각하는 것이다.

두번째 포인트는 일계도 함수에서 찾은 극점이 극댓값인지 극솟값인지를 판단하기 위해 <strong class="r">이계도 미분계수가 음수인지</strong>를 따져야한다는 것이다. 실제로 계산해보면 strictly negative가 나온다.

마지막 세번째 포인트는 <strong class="r">아까 배제했던 양끝의 케이스를 포함할지</strong> 고려하는 것이다. 이 경우 양끝의 케이스를 포함해도 결과식 $$\hat\pi^{\text{MLE}}=\frac{y}{n}$$이 성립한다. 그러나 때로는 성립하지 않아 별도로 표기해야하는 경우도 있다. 이를 잘 확인하자.


출처: 범주형자료분석(STAT343) ㅈㅇㅅ 교수님