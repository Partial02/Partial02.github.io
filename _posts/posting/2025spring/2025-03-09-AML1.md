---
layout: single
title: "[고급 기계학습 1주차] 판별 모델과 생성 모델"
categories: MachineLearning
tag: [ML, DATA303]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    th, td {
        text-align: center;
    }
    .r {
        color: red;
    }
</style>

## Mar 7 (Fri)

첫 데이터과학과 개설 강의! 저번 학기부터 기계학습-고급기계학습-딥러닝-고급딥러닝 순으로 공부할 마음을 먹었기에 수강한 과목이었는데, 옳은 선택이었을까? 아무리 팀플을 제외한 다른 과제가 일절 없다고는 하지만, 좋은 수업이 될지는 모르겠다..

### About Machine Learning

인공지능(AI)이 인간지능을 모방(mimic HI)하는 것이라면, 그 과정에서 <strong class="r">학습이 수반(improve with experience)</strong>되는 것이 머신러닝(ML), 이 과정에서 <strong class="r">신경망(neural networks)이 사용</strong>되는 것이 딥러닝(DL)이다.

의미론적으로는 데이터를 통해 학습(learning from data)하는 것이 기계학습이긴 하지만, 사실 기계학습은 최적화 방법을 찾는 것에 더 가깝다. 그래서 머신러닝은 <strong class="r">학습 과정에 앞서 추론 문제부터 설계</strong>하게 된다.

여기서 추론(inference) 문제란 입력 데이터를 통해 최적의 y값(정답)을 추론하는 것을 의미한다. 수식으로 표현하자면 모수 theta로 주어진 상황 속에서 입력 x를 통해 최적의 y값(일반적으로 최댓값)을 만드는 함수 F를 찾는 과정이다.

$$\hat{\mathbf{y}}= \arg\max_{\mathbf{y} \in \mathcal{Y}} F(\mathbf{y};\mathbf{x},\theta)$$

반면 학습(learing) 문제란 아직 알지 못하는 모수를 학습 데이터를 통해 추정하는 것이다. 수식으로 표현하자면 샘플 데이터의 입력 x와 출력 y를 통해 최적의 모수를 찾는 함수를 추정하는 과정이라 할 수 있다.

$$\hat{\mathbf{\theta}}= \arg\max_{\mathbf{\theta} \in \mathcal{\Theta}} F(\theta;\{\mathbf{x}^n,\mathbf{y}^n\}_{n=1}^N)$$

결국 핵심은 함수 F와 값 y(혹은 모수 theta)가 될 것이다. 상술했듯 기계학습은 최적화 방법을 찾는 것이라고 하였다. 따라서 함수 F와 값 y(혹은 theta)를 정의하는 것이 핵심이고, 이 정의된 F와 y(theta)에 따라 여러 갈래로 분류된다.

#### Supervised / Unsupervised / Reinforcement

지도 학습과 비지도 학습은 최적의 모수 $$\theta ^*$$를 추정하는 과정이다. 다만 지도 학습(supervised learning)은 모수와 입력 x를 통해 출력이 y가 나올 확률이 최대가 되도록 하는 theta star을 찾는 반면, 비지도 학습(unsupervised learning)은 정답 y는 없이, 오직 모수만을 활용해 입력 x가 나올 확률이 최대가 되도록 하는 theta star을 찾아 간다.

한편 강화 학습(reinforcement learning)은 최적의 정책 $$\pi ^*$$을 추정하는 과정이다. 인공지능(COSE361) 시간 때 배운 MDP 내용의 그 정책(policy)이 맞다. 정책을 기반으로 일련의 상태 St에서의 보상 함수(reward function) R의 기댓값이 최대가 되게 하는 정책 pi star을 찾는 과정이다.

구체적인 종류로 지도 학습에는 정답 y가 이산적이면 분류(classification), 연속적이면 회귀(regression)라고 구분한다.

#### Probabilistic / Non-probabilistic

확률을 반영하냐 안하냐로도 ML을 구분할 수 있다.

확률적 학습(probabilistic learning)은 먼저 추론 과정에서 입력 x에 대해 가장 높은 확률을 갖는 출력 y를 찾는다. 이후 학습 과정에서 샘플 입력 x_n으로부터 출력 y_n이 도출될 확률이 가장 높은 정책 theta star를 학습시킨다. 주로 학습 과정에선 최대우도추정(MLE)이나 사후 확률 최대화(MAP)가 적용된다.

반대로 비확률적 학습(non-probabilistic learning)에서는 추론 과정부터 판별 함수(discriminative function)에 확률이 반영되지 않는다. 학습 과정에서도 모델의 복잡도와 오류항만이 사용될 뿐, 여전히 확률이 사용되지 않는다. 학습 방식으로는 에너지 기반 모델(EBM)이나 서포트 벡터 머신(SVM)이 적용된다.

#### Generative / Discriminative

이제 이번주 내용의 핵심인 생성/판별 모델을 알아보자.

생성 모델(Generative Model)은 샘플의 입출력 데이터쌍이 나올 <strong class="r">결합 확률이 최대</strong>(maximum joint prob.)가 되도록 하는 모델링을 하는 과정이다. 식에 x^n과 y^n이 함께 들어가 있는 것에 주목하자.

반면 판별 모델(Discriminative Model)은 실제와 가짜 간의 거리가 최대가 되도록 하는 모델링을 수행한다. 구체적으로는 입력 x^n이 주어졌을 때 가장 적절한 출력 y^n이 나올 조건부 확률 분포를 학습하여, 결정 경계를 찾는 과정이다. 후반부의 식을 보면 앞의 로그우도는 생성 모델과 정확히 같은 식임을 알 수 있다.

대괄호 안의 첫번째 항은 y^n, 즉 ground-truth(참값) 출력이 반영된 것으로, <strong class="r">정답 레이블에 대한 확률을 최대화</strong>하겠다는 의미를 담고 있다. 반면 두번째 항은 y, 즉 참값을 포함하여 가능한 모든 경우의 y에서의 경우를 합산하는데, 이 값이 작을수록 <strong class="r">정답과 오답 간의 차이가 커지게</strong> 되어 더 좋은 모델이 되는 것이다.

한편 점수 함수 F를 활용하여 모델링하는 방법도 있다.

#### Multiway / Structured

출력 y의 특성에 대해서도 분류할 수 있다.

다중 클래스 분류(Multiway)의 경우에는 이진, 혹은 그 이상의 클래스 중에서 가장 확률이 높은 클래스 하나만을 고르는 경우이다. 반면 구조적 예측(Structured)은 여러 출력값 y들 간의 상호작용을 고려하여야 한다. 가령 NLP라면 한 단어의 품사를 보기 위해서는 앞뒤에 온 단어를 같이 고려해야할 수 있을 것이다.

### ML Generalization

머신러닝은 어떤 데이터를 마주하더라도 좋은 성능을 내야한다. 머신러닝의 핵심 요소는 '학습이 수반'된다는 것이었다. 그러니 학습 데이터에 대해서는 당연히 좋은 성능을 낼 것이다. 그러나 기존에 보지 못했던 테스트 데이터에 대해서도 좋은 성능을 내기 위해서는 일반화(generalization)가 되어있어야 한다.

그러나 흔히 과적합(overfitting), 때에 따라서는 과소적합(underfitting)이 발생하곤 한다. fitting이라는 말은 model과 같은 의미로 해석할 수 있는데, 과적합의 경우에는 모델의 변동폭이 크고(<strong class="r">high variance</strong>), 과소적합의 경우에는 모델의 오차가 크다(<strong class="r">high bias</strong>). 이는 데이터를 늘리거나, 파라미터를 줄이거나, 드롭아웃을 진행하거나, 규제(정칙화)를 함으로써 해결할 수 있다.

여기서 규제(Regularization)는 L1/L2 등의 방식으로, 정규화(Normalization)는 사전확률을 정규분포로 가정함으로써 적용할 수 있다. 이때 주황색 정규화 항과 회색 최대우도 항의 수식을 합쳐보면

$$log\;p(\theta)+\arg\max_\theta log\;p(D|\theta)=\arg\max_\theta log\;p(\theta|D)=\text{MAP }\theta^*$$

결국 MAP(Maximum a posteriori Estimation; 최대 사후확률 추정)의 식이 됨을 알 수 있다. 따라서 MAP는 최대우도추정(MLE)과 정칙화(regularization)가 모두 고려된 추정임을 확인할 수 있다. 추가로 MAP의 사전확률(prior)이 정규분포를 따른다고 가정하면, MAP의 정규화 항은

$$p(\theta)=\frac{1}{(2\pi)^{d/2} I^{1/2}}\exp({-\frac{1}{2}}\left\| \theta \right\|_2^2)$$

$$\log p(\theta)={-\frac{1}{2}}\left\| \theta \right\|_2^2+\cdots $$

와 같이 L2 규제와 같아지는 특징이 있다.

### Deep Learning

딥러닝(DL)은 위계가 있는 비선형 특징들을 나타내는 방식이다(영어로 보는 게 더 명확하다. DNNs are hierarchical non-linear feature representations). 입력층에서 시작해 은닉층들을 쌓아올라가며(stacking) 출력층까지 이어지는데, 파라미터들을 통해 출력을 추론하는 과정을 순전파, loss로 부터 그라디언트를 계산해 내려오는 과정을 역전파라고 한다.

순전파(forward propagation for inference) 과정에서는 전달된 데이터에 커널들을 통과시키는 풀링(pooling)이나, 여러 커널들을 하나의 벡터형태로 구성하여 빠른 행렬 계산을 가능케하는 벡터화(vectorization) 과정이 사용된다.

역전파(backward propagation for learning) 과정에서는 상위 은닉층의 그래디언트롤 기반으로 하위 arc의 가중치와 하위 은닉층의 parameter들을 업데이트한다. 보통 가중치는 하나의 식으로, 은닉층의 파라미터는 가중합으로 구성된다.

딥러닝의 가장 큰 특징은 바로 보편근사정리(Universal Approximation Theorem)가 성립한다는 것인데, 여러 비선형 활성화함수를 통해 임의의 함수를 모두 다 모델링할 수 있다.

### Discriminative / Generative Modeling

생성 AI는 이제 우리의 일상 속에 너무나 잘 스며들었다. 이 네 명의 얼굴을 보라. 전부 가짜로 합성된 이미지들이다. 말로 표현만 하면 그에 알맞는 이미지나 영상이 뚝딱 나온다. 물론 이 영상의 경우에는 6명을 넣으라는 지시(instruction)가 제대로 반영되지 못해, 5명만 영상에 등장하는 한계도 보여준다.

판별 모델은 샘플 x(여기선 image)에서 하나의 결과 y(여기선 label)를 도출하는 반면, 생성 모델은 label y에서 나올 수 있는 여러 샘플 x를 일단 고려하고, 그중 확률이 가장 높은 것을 결과로 도출한다.

따라서 생성 모델은 가장 먼저 모수의 분포를 알아내고(represent that distribution), 그후 모델에서 새로운 샘플들을 추출하는 과정으로 구성된다(generate new samples). 이를 각각 <strong class="r">Density Esimation</strong>, <strong class="r">Sample Generation</strong>이라고 표현한다. 전자는 데이터들의 분포를 모방하여 모델의 분포를 생성하고, 후자는 생성한 모델의 분포를 통해 다시 새로운 샘플을 추출한다.

여기서 실제 모델의 분포를 명확히 아는 경우를 explicit density(예: VAE), 정확한 모델은 모르지만 샘플은 알고있는 경우를 implicit density(예: GAN)라 한다.

### Conditional Generative Model by Bayes' Rule

앞서 소개한대로 판별 모델은 image x를 통해 label y를 맞추는 과정이다. 그러나 판별 모델의 한계점은 <strong class="r">불합리한 입력값에 대한 대처가 불가</strong>하다는 것이다. 이진 분류로서 개와 고양이 중에 하나로 분류하라고 지정한다면, 원숭이 사진 등 완전히 다른 입력들을 집어넣더라도 어떻게든 개나 고양이 중 하나로 분류하고 말 것이다.

반면 생성 모델은 각각의 image에 해당하는 확률을 학습한다. 생성 가능한 모든 이미지의 경우를 따지기에, 말도 안되는 입력이 들어온다라도, 고려 대상엔 반영될 지언정 낮은 확률이 책정되기에, 사실상 <strong class="r">불가능한 입력에 대한 거부가 가능</strong>하게 된다. 판별 모델의 한계를 극복해냈다!

조건부 생성 모델(Conditional Generative Model)은 우리가 익히 잘 아는 생성 모델이다. 특정 레이블 y를 제시해주면, 이 레이블에서 가장 확률이 높다고 계산된 이미지 x를 내보낸다. 즉 각각의 레이블들을 통해 모든 이미지들 사이의 경쟁이 일어나는 것이다(a competition among all images).

여기서 재밌는 점은 베이즈 정리를 통해 DM와 GM을 합쳐서 DGM을 반들 수 있다는 것이다. 이는 베이즈 정리를 CGM 식에 적용해보면 알 수 있다.

$$P(x|y)=\frac{P(y|x)}{P(y)}P(x)$$

좌변은 CGM에 대한 식이다. 그리고 이것을 베이즈 정리를 통해 변형하면 분자는 DM, 곱해진 prior P(x)는 GM의 식이 된다. 식을 조금만 더 변형해보면

$$P(x|y)=\frac{P(y|x)}{P(y)}P(x)=\frac{P(y|x)P(x)}{\sum_xP(y|x)P(x)}$$

분모마저 DM과 GM을 통해 구성할 수 있다. 따라서 베이즈 정리를 통해 <strong class="r">DM과 GM으로부터 CGM을 구현</strong>할 수 있다!

<strong class="r">(p.43 잘 이해가 안됨. 중요한 파트이니 교수님께 질문 필요!)</strong>

상술했듯 생성 모델은 모델의 분포를 아느냐 모르느냐에 따라 explicit density와 implicit density로 구분할 수 있다. explicit 중 p(x)를 정확하게 계산할 수 있으면 tractable, 근사분포까지만 알 수 있다면 approximate라고 표현한다. 대표적인 Approximate density로 VAE와 diffusion model이 있다.

한편 implicit은 마르코프 체인, 혹은 direct한 것들이 있는데, 각각 GSN와 EBM(energy-based model), GANs 등이 속한다.

#### Difference between GMs

과거의 생성 모델들은 전체 데이터 분포를 한 번에 학습시키는 whole processing 과정이라 성능이 그리 좋지 못했다. 그러나 최근의 모델(diffusion, autoregressive)들은 각 분포 하나하나를 세분화하여 점진적으로 학습을 시키므로 성능이 월등히 나아졌다.

교수님의 설명을 조금만 덧붙이자면, Flow-based Model은 VAE의 인코더와 디코더를 서로 가역과정(invertible)이 되도록 구성한 것이다. 또한 Diffusion Model은 Energy-based Model 여러 개를 쌓은 것과 유사하다.


출처: 고급 기계학습(DATA303) ㄱㅅㅇ 교수님