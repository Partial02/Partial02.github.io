---
layout: single
title: "[확률 및 랜덤 과정 4주차] 확률변수와 PMF"
categories: Probability
tag: [MATH, COSE382]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    th, td {
        text-align: center;
    }
    .r {
        color: red;
    }
    .b {
        color: blue;
    }
</style>

고등학교 때 배웠던 확률 변수는 그냥 특정 표기법에 불과했다. 아니, 표기도 아니다. 그냥 사건과 동일시 되는 개념으로 배웠던 듯 하다. 그러나 확률 변수를 그렇게 쉽게 정의해도 되는 걸까?

## Sep 23(Mon)

### 확률 변수(Random Variables)

확률이 함수이듯, 확률 변수도 함수이다. 확률 변수는 <strong class="r">표본공간을 정의역으로 하여 실수를 매핑하는 함수</strong>이다. 즉

$$X:S\to \mathbb{R}$$

따라서 P(X=x)라는 것은, {X=x}, 즉 실수 x에 대응하는 집합을 찾아서, 그것을 다시 확률이라는 함수 P(x)에 대입한, 일종의 합성함수인 것이다. 이해가 되는가? 실수->집합->실수로 이어지는 합성함수이다.

확률이 집합에서 폐구간 [0,1]의 값을 리턴하는 함수고, 확률 변수는 집합에서 실수를 리턴하는 함수라면, <strong class="r">확률함수 p(x)</strong>는 실수를 바로 폐구간 [0,1]로 매핑해주는 일종의 지름길이다. 즉 수식으로 보이자면

$$p_X(x)=P(X=x)=P(\{X=x\})=P(X^{-1}(x))$$

이 때문에 우리가 고등학교 때 확률과 확률변수에 대해 자세히 다루지 않은 것이다. <strong class="r">확률함수로 실수에서 실수로의 매핑이 가능</strong>해지기 때문. 또한 집합론을 다루지 않고도 확률함수에 대한 직접적인 미적분 계산이 가능해졌다.

확률변수(r.v.) X의 정의는 정해져있지 않다(unique). 실험자가 자유로이 설정할 수 있다. 이 중에서 확률변수가 discrete(=countable)한 경우를 PMF(확률질량함수)라고 한다. 그렇지 않고 continuous(=uncountable)한 경우를 PDF(확률밀도함수)라고 한다. PMF에서 점 확률은 0이 아니지만, <strong class="r">PDF에서 점 확률은 0</strong>임을 기억하자.

### 확률질량함수(PMF)

확률질량함수 PMF(Probability Mass Function)는 어떤 성질을 지닐까? 기본적으로 확률이므로 0 이상이어야한다(<strong class="r">nonnegative</strong>). 또한 <strong class="r">모든 확률의 합이 1</strong>이어야한다. 수식으로 나타내면

$$\text{Nonnegative: }p_X(x)>0\text{ if }x=x_j\text{ for some j, otherwise }0$$

$$\text{Sums to 1: }\sum_{j=1}^\infty p_X(X_j)=1$$

또한 <strong class="r">집합 A에 대한 확률은 각 케이스의 pmf값의 합</strong>으로 정의된다. 이제 PMF의 종류를 찬찬히 살펴보자(오늘부터 해서 다음 주까지 쭉)

#### 베르누이 분포(Bernoulli distribution)

성공(1: success)과 실패(0: failure)로 정의되는 함수이다. 성공확률 p를 두고 집합 {0, 1}의 두 원소 중 하나가 선택된다. 표기는 다음과 같이 한다.

$$X\sim \text{Bern}(p)$$

$$f_X(x)=p^x(1-p)^{1-x}$$

자매품으로 Indicator(지시함수)가 있다. 지시함수는 특정 원소가 해당 집합에 속하면 1, 아니면 0을 반환하는데, 집합 A의 확률 P(A)는 사실 지시함수로 해석이 가능하다. 즉 지시함수를 포함하는 베르누이 분포에서 모든 확률을 해석할 수 있다. 수식으로는

$$P(A)=P(I_A(s)=1)\gets I_A(s)=1\text{ if }s\in A,\text{ else }0$$

#### 이항 분포(Binomial Distribution)

각각의 독립인 베르누이 분포가 n개 모인 것이다. 확률 p의 여확률을 q라 하면

$$X\sim \text{Bin}(n,p)\to n-X\sim \text{Bin}(n,q)$$

$$f_X(x)=\binom{n}{k}p^x(1-p)^{1-x}$$

#### 이산항등분포(Discrete Uniform Distribution)

유한한 사건의 개수 C에 대하여 각 사건이 동일한 확률(equally likely)을 갖는 경우이다.

$$X\sim \text{DUnif}(C)$$

$$P(X=x)=\frac{1}{\left| C \right|}\to P(X\in A)=\frac{\left| A \right|}{\left| C \right|}$$

### 확률변수의 함수(Functions of r.v.)

확률, 확률변수, 확률함수에 이어 이번엔 확률변수의 함수가 등장했다. 얜 또 뭐냐? 위에서 확률변수는 표본공간 S로부터 실수 전체의 집합 R을 잇는 함수라고 했다. <strong class="r">이 실수 집합 R을 다시 또 다른 실수 집합 R로 매핑</strong>하는 녀석이 확률 변수의 함수이다.

확률변수의 함수가 갖는 의의는, <strong class="r">미지의 확률변수에 적절한 함수를 취함으로써 알고있는 확률변수 및 분포로 변환이 가능</strong>하다는 것이다. 내가 확률변수 Y에 대한 분포를 몰라도, X에 대한 분포를 알고 있으면, 둘의 <strong class="r">일대일대응 함수를 매핑</strong>함으로써 확률을 구할 수 있다는 것이다. 관련한 예제는 필기본 참고


## Sep 25(Wed)

위의 Functions of r.v.를 부가 설명한다. r.v.s. X와 Y간에 y=g(X)라는 관계 함수를 알 고 있다면, Y의 분포를 모르더라도

$$P(Y=y)=P(g(X)=y)=\sum_{x:g(x)=y}P(X=x)$$

라는 방식으로 P(Y)를 구할 수 있고, 만약 함수 g(x)가 1:1 대응, 즉 invertible이라면

$$P(Y=y)=P(X=g^{-1}(y))$$

역함수 방식으로도 접근이 가능하다.

이번엔 두 r.v.s X와 Y를 함께 매핑하는 새로운 함수 g와, 이에 상응하는 또 다른 확률변수 Z:=g(X, Y)를 생각해보자. 이제 확률변수 Z는 표본공간 s를 g(X(s), Y(s))라는 실수집합으로 대응시키게 된다. 역함수 접근은 어렵겠지만, 해당하는 순서쌍 (x, y)의 개수를 셈으로써 P(Z)의 확률도 구할 수 있다.

### 확률변수의 독립(Independence of r.v.)

고등학교 때 배운 사건의 독립은 두 사건 A, B에 대하여 P(A교B)=P(A)P(B)인 경우였다. 그런데 확률변수는 각각의 사건을 모두 다 포함한다. 그렇다면 확률변수의 독립은 좀 다르게 정의되어야하지 않을까? 확률변수는 표본공간을 실수로 매핑하는 함수이기 때문에 차이가 있을 것 같다.

$$P(X\le x,Y\le y)=P(X\le x)P(Y\le y)\text{ for }\forall x,y\in R$$

$$P(X=x,Y=y)=P(X=x)P(Y=y)\text{ for }\forall x,y\in R$$

모든 사건에 대하여 독립일 때 <strong class="r">두 확률변수는 독립</strong>이라고 말할 수 있다. 조금 더 고급지게 말하자면 <strong class="r">결합 분포(Joint Distribution)가 주변 분포(Marginal Distribution)의 곱으로 표현될 때</strong> 두 확률변수는 독립이다.

연속확률변수의 독립을 통해서 이산확률변수의 독립을 유도할 수 있는데

$$P(X\le x)=\sum_{x'=-\infty}^xP(X=x'),P(Y\le y)=\sum_{y'=-\infty}^yP(Y=y')$$

$$P(X\le x)P(Y\le y)=\sum_{x'=-\infty}^x\sum_{y'=-\infty}^yP(X=x'),P(Y=y')\text{ for }\forall x,y$$

이기 때문이다. 셋 이상의 multiple r.v.s.의 경우에도 동일하다.

또한 하나의 확률분포를 따르는 여러 확률변수가 서로 독립인 경우도 있는데, 흔히 <strong class="r">i.i.d.(Independent and Identically distributed)</strong>라고 말한다. 통계학에서 뭐만 하면 가정하는 그 iid.

예를 들어 이항분포 Bin(n,p)는 n개의 i.i.d.인 베르누이 분포 Bern(p)의 합으로 생각할 수 있다.

### 확률질량함수의 기댓값(Expectation of PMF)

앞서 봤던 PMF들과 여기에서 유도되는 PMF들을 더 살펴보자

#### 초기하 분포(Hyper-geometric Distribution)

이항분포를 따르는 두 독립인 확률변수 X, Y는 X~Bin(n,p), Y~Bin(m,p)인데 두 확률변수의 합 X+Y=r이라는 조건이 주어졌다고 하자. 여기서 <strong class="r">조건부 확률질량함수(Conditional PMF)</strong> $$P(X=x|X+Y=r)$$은 어떤 분포를 따를까? 일단 두 변수는 독립이므로 X+Y~Bin(n+m,p)임을 알 수 있다. 이제 베이즈 정리를 적용하면

$$P(X=x|X+Y=r)=\frac{P(X+Y=r|X=x)P(X=x)}{P(X+Y=r)}=\frac{P(x+Y=r|X=x)P(X=x)}{P(X+Y=r)}$$

인데 변수 X와 Y는 서로 독립이므로 조건부를 없앨 수 있다. 따라서

$$=\frac{P(Y=r-x)P(X=x)}{P(X+Y=r)}=\frac{\binom{m}{r-x}p^{r-x}(1-p)^{m-r+x}\binom{n}{x}p^{x}(1-p)^{n-x}}{\binom{n+m}{r}p^{r}(1-p)^{n+m-r}}$$

여기서 p와 1-p에 관련한 식이 모두 소거되므로 정리하면

$$P(X=x|X+Y=r)=\frac{\binom{n}{x}\binom{m}{r-x}}{\binom{n+m}{r}}\sim HGeom(n,m,r)$$

다음과 같은 PMF를 <strong class="r">초기하 분포(Hypergeometric Distribution)</strong>라 한다. 즉 n+m개 중에서 총 r개를 뽑는데, 그 중 x개는 n개에서, 나머지 r-x개는 m개에서 뽑는다는 의미

### 이산확률변수의 기댓값

잘 알려져있듯 

$$E(X)=\sum_{j=1}^\infty x_jP(X=x_j)=\sum_xxp_X(x)$$

가 기댓값에 대한 식이다. 기댓값은 선형성(linearity)을 지니기에 독립을 고려하지 않고도 확률변수간의 합이나 상수곱을 밖으로 뺄 수 있다. 간단한 기댓값들을 살펴보면

$$X\sim DUnif({1,2,3,4,5,6})\to E(X)=\frac{1+2+3+4+5+6}{6}=3.5$$

$$X\sim Bern(p)\to E(X)=1p+0(1-p)=p$$

$$X\sim Bin(n,p)\to E(X)=np$$

이항분포의 평균이 np임은 상술한 'N개의 iid인 베르누이분포의 합'으로도 생각할 수 있고, 조합과 이항정리를 적용하여 증명할 수도 있다. 이제 좀 더 복잡한 분포와 그에 따른 기댓값들을 살펴보자.

#### 기하 분포(Geometric Distribution)

기하 분포는 x번 실패 이후 최초로 성공할 확률을 말한다. 이때 각 trial의 성공 확률을 p라고 하면

$$X\sim \text{Geom}(p)$$

$$P(X=k)=(1-p)^{k}p$$

자매품으로 FS 분포(First Success Distribution)가 있다. 기하 분포에서 실패 횟수가 x번이 아닌 x-1번으로 바뀐 것이다. 즉 x번째에 최초로 성공할 확률이다. r.v. Y로 나타내자면 표기는

$$Y\sim \text{FS}(p)$$

$$y(X=k)=(1-p)^{k-1}p$$

여기서 둘의 관계를 잘 생각해보자. X번 실패 후 최초로 성공한다는 것은 총 X+1번 시도했다는 뜻과 같다. 따라서 <strong class="r">X~Geom(p)이면 X+1~FS(p)</strong>이고 <strong class="b">Y~FS(p)이면 Y-1~Geom(p)</strong>이다.

기하분포의 기댓값은 q/p인데 증명해보자. 무한등비급수의 합 $$\sum_{k=0}^\infty(1-p)^k=\frac{1}{p}$$에서 p로 미분하면

$$\sum_{k=0}^\infty k(1-p)^{k-1}=\frac{1}{p^2}$$

양변에 pq를 곱하면 기하 분포의 기댓값 식이므로

$$E(X)=\sum_{k=0}^\infty k(1-p)^{k}p=p(1-p)\frac{1}{p^2}=\frac{1-p}{p}$$

앞서 다룬 기하 분포와 FS 분포의 관계에 따라

$$E(Y)=E(X+1)=E(X)+1=\frac{1-p}{p}+1=\frac{1}{p}$$

즉 FS 분포의 기댓값은 확률의 역수가 된다. 기하 분포와 FS분포에 대한 예제들은 필기본 참조


출처: 확률및랜덤과정(COSE382) ㅈㅇㅈ 교수님
