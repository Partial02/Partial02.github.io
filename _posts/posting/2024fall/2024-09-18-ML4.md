---
layout: single
title: "[기계학습 3주차A] 베이즈 결정이론 & 최대우도추정"
categories: MachineLearning
tag: [ML, COSE362]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    th, td {
        text-align: center;
    }
    .r {
        color: red;
    }
</style>

## 3주간 깃허브 정리를 하면서 드는 생각

시간이 너무 많이 든다. 배우는 시간보다 깃허브에 정리하는 시간이 더 많은 것 같다. 1시간 15분짜리 수업을 정리하는데 그보다 더 많은 시간이 들다 보니, 내가 대학을 2개 다니는 듯한 부담이 있다. 그래서 이제부터는 특기할만한 내용만 적기로 했다.

내가 나중에 필기본을 봤을 때, '이게 왜 이랬더라?'하는 것들만 기록해야겠다. 이 생각은 Reject action부터 적용한다(9/22) 

앞서 베이지안 분류(Bayesian Classification)의 결론은 Posterior가 큰 쪽으로 분류하면 된다는 것이었다. 그런데 이게 유일한 기준이 될 수 있을까? 정말로 <strong class="r">Posterior가 큰 쪽으로 하는 것만이 유리할까?</strong>

## 베이즈 결정이론(Bayesian Decision Rules)

분류에 있어 위양성과 위음성의 에러가 있지만, 이 둘의 경중이 다를 수 있다. 가령 병에 안 걸린 사람에게 걸렸다고 진단하는 것은 큰 오류겠지만, 병에 걸린 사람에게 안 걸렸다고 오진하는 것은 치명적인 에러가 될 수 있다. 따라서 에러의 개수만을 작게 하는 것보다도, <strong class="r">risk가 가장 작게</strong> 하는 것이 중요하다.

입력 x를 클래스 $$c_i$$로 분류하는 action을 $$\alpha_i$$라고 하고, 실제 x는 클래스 k에 속한다고 하자. 이때 클래스 k에 속하는 입력 x를 클래스 i로 분류하였을 때 발생하는 비용(loss;cost)을 $$\lambda_{ik}$$라고 두면 risk의 평균(=기댓값)을 R이라 하면

$$R(\alpha_i|x)\equiv \sum_k\lambda_{ik}P(c_k|x)$$

즉 입력을 k클래스로 분류할 확률과 그에 따른 loss를 곱하여 다 더한 것이 평균 risk가 된다. 이때

$$\text{Choose }\alpha_i\text{ if }i=arg \min_{i'} R(\alpha_i|x)$$

risk가 최소가 되는 인덱스 i로 클래스를 판단하는 방법을 <strong class="r">Bayesian Decision Rule</strong>(베이즈 결정 규칙; Bayes Estimator)이라 한다.

### 베이즈 결정이론: 이진분류의 경우

베이지안 분류와 베이즈 결정이론을 합쳐서 생각하면

![binary_decision]({{site.url}}/images/MacLea/bayesian_decision_binary.png)

차근차근 이해해보자. 우리는 리스크가 작은 쪽으로 클래스를 분류할 것이다(1번째 줄). 이 리스크는 '1을 1로 판단+2를 1로 판단' 과 '1을 2로 판단+2를 2로 판단'으로 sigma를 풀어서 생각할 수 있다(2번째 줄).

양변을 확률에 맞춰 동류항끼리 묶고 다시 정리하는데(3번째 줄), 이때 올바르게 분류할 때의 리스크가 더 작은 것이 당연하므로 $$\lambda_{11}-\lambda_{21}<0$$이다. 따라서 부등호 방향이 바뀜에 유의하자(4번째 줄).

베이즈 정리를 활용하여 기존의 조건부 확률을 변환하고(5번째 줄), prior를 우측으로 곱하여 넘기면(6번째 줄) 좌변에 놓인 것은 베이지안 분류에서 봤던 likelihood ratio, 즉 상수값이 된다.

이제 양변에 로그를 취한 뒤 정리해주면 <a href="https://partial02.github.io/machinelearning/ML3/">이전 장</a>의 log likelihood ratio보다 $$log\frac{(\lambda_{22}-\lambda_{12})}{(\lambda_{11}-\lambda_{21})}:=\theta$$가 붙는데, 이를 theta로 정리해주자.

만약 $$\left| \lambda_{12} \right|>\left| \lambda_{21} \right|$$라 하면 진수의 분자 부분이 분모보다 커지므로 진수는 1보다 크고, theta는 양수가 된다. 따라서 우변이 더 커지므로 클래스를 2로 분류할 공산이 더 커진다.
이는 2를 1로 분류했을 때의 리스크 <strong class="r">$$\lambda_{12}$$가 더 크므로 2로 분류</strong>하는, 지극히 당연한 현상으로 볼 수 있다! 

### 베이즈 결정이론: 0/1 Loss의 경우

이번엔 다중 클래스 분류이지만 loss가 올바르게 분류하면 0, 아니라면 1로만 정해져있다고 하자. 쉽게 말하면

$$\lambda_{ik}=\begin{cases}0\quad\text{if }i=k\\1\quad \text{if }i\neq k\\ \end{cases}$$

이때 risk에 대한 식은 $$\lambda_{kk}=0$$이므로

$$R(\alpha_i|x)=\sum_{k}\lambda_{ik}P(c_k|x)=\sum_{k\neq i}P(c_k|x)=1-P(c_i|x)$$

이고, risk가 최소가 되는 인덱스 i를 찾는 것은

$$arg\min_iR(\alpha_i|x)=arg\min_i[1-P(c_i|x)]=arg\max_iP(c_i|x)$$

다음과 같이 음의 부호를 없애는 과정에서 arg max로 바뀐다. 즉 risk가 최소가 되는 인덱스를 찾는 과정에서, 확률이 최대가 되는 인덱스를 찾는 Maximum posterior probability classification으로 바뀐 것 뿐이다. 이름만 거창하다.

결론을 말하자면, 0/1 Loss와 같이 <strong class="r">모든 에러의 경중이 같다면, minimum risk나 maximum posterior이나 같은 이야기</strong>가 된다는 것.

### 베이즈 결정이론: Reject action의 경우

여기는 내가 잘 이해한 게 맞는지 모르겠다. 핵심은 'AI가 스스로 판단할 때의 risk'와 '사람이 개입하여 판단할 때의 risk' 중 더 loss가 적은 것을 선택하겠다는 것이다.

AI가 판단하면 앞서 말한대로 $$R(\alpha_i|x)=\sum_{k=1}^K\lambda_{ik} P(c_k|x)=1-P(c_i|x)$$이고, 사람이 개입할 때(i = K + 1)의 loss를 그냥 lambda라고 하면, 모든 케이스에 사람이 개입하니 전사건의 확률 1에 대해서

$$R(\alpha_i|x)=\sum_k\lambda_{ik}{(c_k|x)}=\lambda\sum_{k=1}^KP(c_k|x)=\lambda$$

이므로 둘 중 더 risk가 적은 것을 채택한다는 것이다. 사람의 개입에는 비용이 들지만, 그것을 고려하더라도 AI에 비해서 risk가 적어진다면, 사람을 고용하게 되는 것이다.

## Discriminant Function

위에서 말한 모든 posterior, 혹은 베이즈 정리 꼴의 prior * likelihood 등의 함수를 이제 <strong class="r">discriminant function</strong>이라 할 것이다. 최소가 되는 것을 구할 수도 있고, 혹은 최대가 되는 것을 구해야할 수도 있다.

이 각 함수에 따라서 총 K개의 클래스 중 i번째의 클래스에 속할 확률이 가장 높다고 하자. 그렇다면 당연히 우리는 그 케이스를 i번째 클래스로 분류해야할 것이다. 이렇게 분류한 영역을 <strong class="r">결정 영역(decision region)</strong>이라 하고, 그 영역 간의 경계를 <strong class="r">결정 경계(decision boundary)</strong>라 한다.

만약 이진 분류라고 하면 우리는 새로 <strong class="r">Dichotomizer</strong>라는 용어로 이진 분류기를 표현할 수 있다. 1번 클래스와 2번 클래스에 속할 각각의 확률을 뺀 것을 $$g(x)\equiv g_1(x)-g_2(x)$$라 하면 g가 양수이면 1번 클래스로, 그렇지 않다면 2번 클래스로 분류하는 등으로 생각하는 것이 dichotomizer다.

만약 multi-class라면 polychotomizer라고 부른다.

## 최대우도추정(MLE: Maximum Likelihood Estimation)

우리가 통계적으로 하고자 하는 추정은 결국 모수를 알려고 하는 것이다. 그러나 모수는 알려져 있지 않다. 따라서 우리는 확률 데이터(알고있는 값) x로 부터 모수(모르는 값) theta를 추정하려고 하는데, 이 방법론을 <strong class="r">Parametric Method</strong>라고 한다.

그렇다면 알고있는, 관측한 상수 data인 x를 통해서 알지 못하는 모수(unknown parameters)를 추정하는 모델을 어떻게 설계하면 좋을까?

이제부터 각 모수가 theta인 상황에 대해서 데이터셋 D가 발생할 확률, 즉 $$P(D|\theta)$$를 <strong class="r">우도(likelihood)</strong>라고 표현하겠다. 데이터 D는 n개의 알고 있는 값인 관측 데이터 x로 구성되어있다. 여느 통계 모델이 그러하듯, IID를 가정하면 (앞으로 특별한 언급이 없다면 IID로 고정한다)

$$P(D|\theta)=p(x^1,x^2,\cdots,x^N|\theta)=\prod_{t}P(x^t|\theta)$$

로 고쳐쓸 수 있다. 계산 편의를 위해(확률함수들은 지수함수 꼴이 대부분이라 그렇다) 로그를 취해주고 argmax를 붙여준

<strong class="r">$$arg\max_\theta P(D|\theta)=arg\max_\theta\prod_{t}P(x^t|\theta)=arg\max_\theta\sum_{t}log P(x^t|\theta)$$</strong>

를 앞으로 <strong class="r">최대 우도 추정법(MLE)</strong>라 부르겠다! 우도가 가장 높은 쪽으로 클래스를 추정한다는, 지극히 상식적인 이야기이다. 이제 각 모델들에 MLE를 적용해보자.

### MLE: 베르누이 분포를 따를 때

가장 기초적인 상황인 이진 분류 시의 MLE를 먼저 다뤄보자. 0 또는 1로 분류할 때 클래스 1에 속할 확률이 theta면, 0에 속할 확률은 1-theta이므로 기본적인 베르누이 분포 모델은

$$P(x|\theta)=\theta^x(1-\theta)^{1-x}$$

이다. 여기에 MLE를 취한 뒤 편미분을 해주면 결론은

$$\sum_t[x^t-\theta]=0$$

에서

<strong class="r">$$\theta=\frac{\sum_tx^t}{N}$$</strong>

이 된다. 생각해보면 당연하다. 당연히 전체 개수 N 중에 해당하는 개체의 개수가 그 베르누이 분포의 확률이 될 것이다. 다만 이 계산의 의의는, 상식적인 내용을 수식으로써 입증해냈다는 것이다.

### MLE: Categorical Distribution를 따를 때

이제 클래스가 K개인 상황을 가정해 볼 것인데, 그 전에 <strong class="r">라그랑주 승수법(Lagrange Multiplier Method)</strong>을 이해해야한다.

핵심은, 최적화하고자 하는 함수 f의 최적값은 편미분으로 구해지지만, 이 경우 제약조건인 g(x)가 추가로 있다는 것이다. 그러면 어떻게 해야하냐?

$$L=f(x)-\lambda g(x)$$와 같이 두 함수 f와 g를 lambda의 곱으로 빼서, $$\nabla L=0$$이 되게, 즉 그라디언트가 같아지게하는 x와 람다(라그랑주 승수)를 찾는 것이다. x는 그라디언트의 방향을 같게 하는데에 쓰이고, 람다는 길이가 다른 두 벡터의 크기를 맞춰주는 역할을 한다. 자세한 것은 강의 자료의 수식을 보면 이해가 될 것이다.

수식에서 $$\nabla f=<2x_1, 2x_2>, \nabla g=<1,1>$$이므로 델 f와 델 g의 방향을 맞추기 위해 x_1=x_2=1/2이 되어야 하며, 이때 두 벡터의 크기는 같으므로 람다는 1이 될 것이다. 이제 수식으로 parameter theta_i의 값을 추정해보자.

이진분류의 베르누이분포와 반대되는 분포이기에, 카테고리 분포는 Multinoulli 분포라고도 불린단다. 이건 뭐 여담이고

여기서 우도 P는 입력 x의 클래스를 i로 판단했을 때의 확률만을 곱한 값이다. 뭐 당연하다. 그런데 이때 붙는 제약조건(constraint)은, 각 클래스에 속하는 확률을 모두 더하면 1이 되야한다는 것이다(이것도 뭐 당연하다). 수식으로 보이면

$$P(x=v_i)=\theta_i\text{에서 }P(x|\theta)=\prod_i\theta_i^{1(x=v_i)}\text{인데 }\sum_i\theta_i=1$$

이제 MLE를 적용하는데 라그랑주 방법을 적용해야하므로, 라그랑주 함수 L에다가 우도와 제약조건(각 클래스 확률의 합은 1)을 람다로 곱하여 연결해주는 과정이 수반된다. 이제 확률 theta_i와 라그랑주 승수 lambda로 수식을 편미분해주면 결론은

$$\theta_i=\frac{\sum_t1(x_t=v_i)}{\lambda}\text{, for all i}$$

의 수식이 총 클래스의 개수인 K개가 나오고,

$$\sum_i\theta_i=1$$

이라는 자기 조건이 다시 나오게 된다. 이 두 조건을 연립 후 시그마의 순서를 바꿔주면

<strong class="r">$$\theta_i=\frac{\sum_t1(x_t=v_i)}{N}\text{, for all i}$$</strong>

라는 결론을 얻는다. 이 역시 당연하다. 클래스에 속하는 개수 만큼 확률이 나올테니까

### MLE: 지도 학습의 경우



<strong class="r"></strong>


