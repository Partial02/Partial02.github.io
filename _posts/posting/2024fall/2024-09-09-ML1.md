---
layout: single
title: "[기계학습 1주차] 정정 성공"
categories: Probability
tag: [MATH, COSE382]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    th, td {
        text-align: center;
    }
    .r {
        color: red;
    }
</style>

## 정리하기에 앞서..

원래 기계학습을 수강할 생각은 없었지만, 수강신청에서 데이터베이스를 못 잡는 바람에 들을 전공 하나가 비게 되었다. 그래서 인공지능->기계학습 / 컴퓨터구조->운영체제로 이어지는 커리큘럼 중 하나를 동시에 수강하려고 하였는데..

인공지능은 잡고 컴퓨터구조를 못잡으면서 기계학습과 운영체제를 어쩔 수 없이 수강하게 되었다.

하지만 ㄱㅎㅊ 교수님의 기계학습은 필기를 알아보기 어렵다는 평이 많았고, ㅊㅅㄱ 교수님의 운영체제는 내가 이해하기에는 너무 양이 많고 진도가 빨랐다. 그래서...

지난 수요일 학년 정정을 통해서 기계학습을 육동석 교수님걸로 정정하고 2주차부터 수업을 듣게 되었다.

따라서 이 1주차 정리는 사실 강의를 듣지 않고 내 마음대로 정리한 것이라는 말!

## Syllabus

일단 이번 학기에 수강하는 과목 중 하나 빼고 다섯 개가 모두 절대평가(!!)인데, 기계학습도 절대평가이다.

과제가 4개 예정되어 있는데, 과제가 있을 시 중간 30%, 기말 30%, 과제 30%, 퀴즈&출석 10% 정도로 조정하실 생각이라고.

grading 방식이 확정된 것은 아니어서 나중에 정확히 나오는 것을 기다려봐야할 듯.

오늘 알았는데 블보에 자율출석 방식이다. 오늘 안 찍었는데.. 난 몰라

## 1주차 요약

### Introduction

#### 기계학습(Machine Learning)이란?

일단 ML(기계학습)과 AI(인공지능)의 차이는 '<strong class="r">규칙을 누가 정하느냐</strong>'이다.

머신러닝은 프로그램이 규칙을 자체적으로 생산하는 반면, 인공지능은 인간이 직접 규칙을 설계하여 알려주고, 그것을 기반으로 AI가 판단한다.

ML이 AI의 하위 개념임을 생각하면 ML이 AI의 발전된 단계라는 것을 말씀하고 싶으신 듯

ML의 4가지 특징은 다음과 같다.

<div class="notice--info">
<h4>기계학습의 4가지 특징</h4>
<ol>
<li>데이터에서 패턴을 찾아 미래를 예측한다(<strong class="r">detect</strong> patterns in data to <strong class="r">predict</strong> future data)</li>
<li>학습을 통해 스스로를 알아서 개선한다(automatically <strong class="r">improve</strong> themseleves with experience)</li>
<li>파라미터를 최적화한다(to <strong class="r">optimize</strong> the parameters)</li>
<li>예측이나 답변을 위해 쓰인다(<strong class="r">predictive</strong> to make predictions in the future, or <strong class="r">descriptive</strong> to gain knowledge from data, or both)</li>
</ol></div>

기계학습은 크게 지도 학습, 비지도 학습, 강화 학습으로 나뉘는데 간단히 정리하면 다음과 같다.

<table border="2" >
    <th width="15%">ML 종류</th>
	<th width="30%">수식 표현</th>
	<th>설명</th>
	<tr><!-- 첫번째 줄 시작 -->
        <td bgcolor="LightCoral">지도 학습(Supervised Learning / Predictive Learning)</td>
	    <td>$$D=\left\{x^t, y^t\right\}_{t=1}^N$$
        x: input(feature, attribute, or covariate), y: output(label or response variable), D: data</td>
        <td>input과 output의 pair의 집합이다. y가 있으므로 <strong class="r">정답이 있는 학습</strong>이다. 범주형 output의 분류(Classification)와 실수형 output의 회귀(Regression)로 나뉜다.</td>
	</tr><!-- 첫번째 줄 끝 -->
	<tr><!-- 두번째 줄 시작 -->
        <td bgcolor="LightCoral">비지도 학습(Unsupervised Learning / Descriptive Learning)</td>
	    <td>$$D=\left\{x^t\right\}_{t=1}^N$$</td>
        <td><strong class="r">정답이 없는 학습</strong>이다. 패턴을 추출한다</td>
	</tr><!-- 두번째 줄 끝 -->
    <tr><!-- 세번째 줄 시작 -->
        <td bgcolor="LightCoral">강화 학습(Reinforcement Learning)</td>
        <td>-</td>
	    <td>정답이 있는지 없는지 조차 모르지만 매순간 ML은 성능 개선에 최선을 다하는 학습. 자기가 수행한 결과가 reward인지 punishment인지 구혈하여 reward를 최대화하려한다.</td>
	</tr><!-- 세번째 줄 끝 -->
    <tr><!-- 네번째 줄 시작 -->
        <td>준지도학습(Semi-supervise Learning)</td>
	    <td>-</td>
        <td>지도 학습이 비싸기 때문에, 초반에는 소규모로 지도학습을 하다, 점차 비지도학습으로 규모를 키운 경우에 해당한다. 경제적 이유로 인한 선회</td>
	</tr><!-- 네번째 줄 끝 -->
    <tr><!-- 다섯번째 줄 시작 -->
        <td>자기지도학습(Self-supervise Learning)</td>
	    <td>-</td>
        <td>label이 없는 데이터를 스스로 label을 만들어서 학습한다.</td>
	</tr><!-- 다섯번째 줄 끝 -->
</table>

#### 분류와 회귀

분류(Classification)는 흔히 이진 분류(Two-class, binary) 처럼 0(negative)과 1(positive)로 구별하는 방식이나, 세 개 이상의 클래스로 나누는 Multiclass classification, 한 instance가 여러 클래스에 동시에 해당이 되는 Multilabel classification이 있다.

회귀(Regression)는 수치형 데이터를 내놓는 지도학습의 한 방식으로, 사실 regression과 classification은 근사를 통해 비슷하게 사용할 수 있다. (아마 로지스틱 회귀와 이진 분류의 관계를 말하는 듯)

#### 비지도 학습과 강화 학습

비지도 학습은 상술했듯 label이 없는 학습이다. 보통 잠재요인분석(Latent Factors)과 차원 축소(Dimensionality Reduction)가 주된 갈래인데, 하나의 예로 주성분분석(PCA; Principal Component Analysis)이 있다.

강화 학습은 '현재 상태(state)를 인지'하고 '강화 학습을 수행(action)'하는 state-action의 반복이다. 항상은 아니지만 때때로 reward가 발생하는데, 이를 적절히 통제하는 policy로 강화 학습이 가능하다.

예를 들어 벽돌깨기 게임을 한다고 하면, '점수를 높여오라'라는 policy를 통해 알아서 점수가 높아지는 강화학습이 실현되는 것.

이외에도 ML의 갈래로 생성 모델(Generative Models)이라는 것이 있다. 이미지를 합성해 적절히 생성하거나(Image Synthesis), 음성을 모방하여 합성하거나(Speech Synthesis), 기존 이미지에 다른 이미지를 덧입히고(Image Translation), 해상도를 높이거나(Super Resolution), 자연스럽게 이미지를 편집(Image Inpainting)하고, 음성을 인코딩하는(Voice Conversion)하는 것 모두가 생성 모델의 일종이다.

#### 그래서 기계학습을 왜 쓰는데?

ML을 사용하는 이유는 다음과 같다.

<div class="notice--success">
<h4></h4>
<ol>
<li>손으로 코딩을 할 수 없는 정도의 문제를 해결하기 위해</li>
<li>전문지식이 없어서 해결책을 모르는 경우</li>
<li>전문지식이 있지만 해결이 안되는 경우</li>
<li>solution이 계속 바뀌어서 인간이 지정하기엔 어려울 때</li>
</ol></div>


### Terminologies

#### 우리 가족이 탈 차는 뭘로?

![familyCar]({{site.url}}/images/2024-09-09-ML1/family_car_plot.png)

다음과 같이 한 가족이 탈 차를 선정하는 도식을 살펴보자. +로 표기된 건 살 만한 차(positive), -로 표기된 건 사지 않을 차(negative)이다. 판단 기준은 x1축의 가격과 x2축의 마력이다.

이렇게 클래스를 두고 학습을 시키는 것을 <strong class="r">Concept Learning</strong>이라고 한다. 여기서 Concept은 Class라고 이해하면 된다. 클래스가 나온다? 이거 지도학습 중에서도 분류잖아.

따라서 $$D=\left\{x^t, y^t\right\}_{t=1}^N$$라는 ML model을 따라간다. 이때

input $$x^t = [x_1^t \cdots x_d^t]$$이고 (d는 input인 x^t 벡터의 길이이고, 여기선 d=2이다.)

output $$r^t=\begin{cases}
    1\quad \text{if}\;x^t\;\text{is a positive example}\\
    0\quad \text{if}\;x^t\;\text{is a negative example}\\
  \end{cases}$$ 이다.

여기서 분류하고자 하는 범주를 Target concept, 혹은 target class, target function이라고 하는데 현재 target은 0과 1로 구분되어 있지만, 그 범위를 모르는 상태이다. 따라서 적절한 범위를 지정하는 p1, p2, e1, e2를 지정하기 위하여 ML이 사용되어야 한다.

#### 가설 공간

앞으로 가설(Hypothesis)이라고 하면 학습 알고리즘에 의해 만들어진, 분류를 하는 '<strong class="r">판단 근거</strong>'를 지칭하는 말로 이해하면 된다.

![familyCarError]({{site.url}}/images/2024-09-09-ML1/family_car_plot_error.png)

다음과 같이 파란색의 label 범위와 노란색의 가설 범위가 있다고 하자. 위양성(False positive)는 사도 되지만 사지 말자고 판단한 경우, 위음성(False negative)은 사면 안되지만 사도 된다고 판단한 경우를 의미한다.

이때 에러의 종류로 일반화 에러와 실증적 에러가 있는데, 일반화 에러(Generalization error)는 현재까지는 문제가 없으나, <strong class="r">데이터가 추가되면 드러나는 에러</strong>를 의미한다. 즉 노란색의 가설범위가 틀렸다는 것인데, 현재까지의 instance로는 알 수 없는 것

이와 달리 실증적 에러(Empirical error)는 실제로 <strong class="r">값이 틀린, 현재 확인할 수 있는 에러</strong>를 의미한다. 즉 위음성과 위양성 instance가 있으면 그것이 실증적 에러인 셈.

이 실증적 에러는 다음과 같이 수식으로 표현 가능한데,

$$E(h|D)=\sum_{t=1}^{n}1(h(x^t)\neq r^t)$$

해석하자면, 가설 h와 데이터 D에 대하여, 입력 x^t에 대한 가설에서의 예측 값 h(x^t)와 실제 레이블인 r^t 값이 다른, 즉 empirical error가 발생한 개수를 모두 더한 값을 E(h|D)라고 표현한다는 것

이처럼 입력 x가 들어왔을 때 그에 대한 출력 값이 존재할 수 있는 가설의 집합을 <strong class="r">가설 공간(Hypothesis space / Hypothesis class)</strong>이라 하며 대문자 H로 표기한다. 여기서 가설 공간 H는 1사분면이 되는 것

#### Version Space

앞서 눈에 보이는 에러를 Empirical Error라고 했다. 이런 실증적 에러가 없는 경우의 가설을 <strong class="r">Consistent Error</strong>라고 하는데 수식으로는

$$\text{CONSISTENT}(h, D) \equiv \forall (x,r)\in D[h(x)=r]$$

해석하자면 입력 x에 대한 가설 h의 값이 label r과 일치하는 데이터 D에 모든 (입력, 출력) 쌍이 존재한다는 것이다. 말 그대로 empirical error가 없는 가설은 consistent한 것이다.

이때 가장 좁은, 즉 consistent를 가장 잘 설명하는 가설을 Most specific hypothesis(줄여서 <strong class="r">s</strong>), 가장 큰 가설을 Most general hypothesis(줄여서 <strong class="r">g</strong>)라 하며, g보다 크고 s보다 작은 모든 집합을 <strong class="r">Version space</strong>라 한다.

수식으로는

\text{VS}_{\mathcal{H, D}}\equiv \{ h\in \mathcal{H}|\text{CONSISTENT}(h,\mathcal{D}) \}

즉, 가설 공간에 속한 가설 h 중 <strong class="r">모든 consistent한 가설을 모은 공간</strong>이 Version Space다.

또는

\text{VS}_{\mathcal{H, D}}\equiv \{ h\in \mathcal{H}|\exists s\exists g[s\le h\le g] \}

가설 공간에 속한 가설 h 중 s(specific)와 g(general) 사이에 있는 가설들을 모은 것이다. (그게 그거다)

이때 s와 g의 거리, 즉 positive 중에 중심에서 가장 먼 값과 negative 중에서 중심에서 가장 가까운 값의 차를 Margin이라 한다.

보통 우리가 사용하는 가설은 (당연히 가설 공간 H에 속하고) consistent한 가설 중, 적당한, 즉 s와 g의 평균값을 가설로 채택한다.

#### VC Dimensions




