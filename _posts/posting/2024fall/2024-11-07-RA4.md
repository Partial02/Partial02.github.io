---
layout: single
title: "[회귀분석 9주차] 가우스-마르코프 모델 & 순서형 변수"
categories: Statistics
tag: [STAT, STAT342]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    th, td {
        text-align: center;
    }
    .r {
        color: red;
    }
</style>

못 푼 문제는 있지만 그래도 뭐든 채우고 나와서 시험을 잘봤다고 생각했는데, 생각보다 틀렸나보다. 그나마 Q3 안에 들긴 했지만, 생각보다 8-90점대를 받은 사람들이 있는 편. 더 분발해야할 듯

## Nov 1 (Fri)

수업을 시작하시면서 중간고사 문제 4, 5번을 풀어주셨는데, 푸는 의도가 아마 '많은 학생들이 이 문제를 틀려서'일 것으로 예측이 갔다. 정답. 시험이 좀 어려웠냐고 하시면서 기말고사는 조금 더 쉽게 출제하신다고 하셨다. 근데 풀이하시는 거 보니까, 난 못 풀겠더라. 저걸 다 생각해서 유도한다는 것이 되는 구나..

이번 수업엔 갑자기 강의 노트가 아닌 강의 쪽지(?) 비슷한 note pdf로 강의를 시작하셨다. 초반엔 평균 벡터, 분산-공분산 행렬 등 아는 내용이라서 패스.

### Gauss-Markov model

상수 행렬 A와 상수 열벡터 c, d가 있다고 하자. 어떤 벡터 y가 있다면, 그 벡터의 선형결합에 대한 평균과 분산은

$$E(Ay+d)=A\mu+d$$

$$Var(Ay+d)=A\Sigma A^T$$

$$E(c^Ty)=c^T\mu$$

$$Var(c^Ty)=c^T\Sigma c$$

뭐 잘 알고 있던 내용이다. 한편 설명변수(X)들이 포함된 설계행렬(Design Matrix) 모델을 생각해보자.

$$y=X\beta+\epsilon$$

$$\begin{bmatrix} 
   y_1 \\ y_2 \\ \vdots\\ y_n
   \end{bmatrix}=
\begin{bmatrix} 
   X_{11} & X_{12} & \cdots & X_{1p} \\
   X_{21} & X_{22} & \cdots & X_{2p} \\
   \vdots & \vdots & & \vdots \\
   X_{n1} & X_{n2} & \cdots & X_{np} \\
   \end{bmatrix}
\begin{bmatrix} 
   \beta_1 \\ \beta_2 \\ \vdots\\ \beta_p
   \end{bmatrix}+
\begin{bmatrix} 
   \epsilon_1 \\ \epsilon_2 \\ \vdots\\ \epsilon_p
   \end{bmatrix}$$

이때 $$E(\epsilon)=0, Var(\epsilon)=\sigma^2I$$라고 가정하자. 즉 이 뜻은

$$E\begin{bmatrix} 
   \epsilon_1 \\ \vdots\\ \epsilon_n
   \end{bmatrix}= \begin{bmatrix} 0 \\ \vdots\\ 0 \end{bmatrix}$$

$$Var(\epsilon)=Cov[\begin{bmatrix} 
   \epsilon_1 \\ \vdots\\ \epsilon_n
   \end{bmatrix}\begin{bmatrix} 
   \epsilon_1 \\ \vdots\\ \epsilon_n
   \end{bmatrix}^T]=\begin{bmatrix} 
   \sigma^2 & 0 & \cdots & 0 \\
   0 & \sigma^2 & \cdots & 0 \\
   \vdots & \vdots & \ddots & \vdots \\
   0 & 0 & \cdots & \sigma^2 \\
   \end{bmatrix}$$

라는 것이다. 오차의 공분산 행렬이 대각 원소들은 모두 시그마 제곱이고, off-diagonal들은 모두 0이라는 것은 모든 오차가 서로 독립이며 iid임을 의미한다. 즉

$$\epsilon_i \bot \epsilon_j (i.i.d), \forall i,j$$

이때 위의 설계 행렬 X와 회귀계수 벡터 beta는 모두 상수(관측값)이므로 기댓값과 분산에서 상수로 유지되기에

$$E(Y)=E(X\beta+\epsilon)=X\beta, Var(Y)=Var(\epsilon)=\sigma^2I$$

따라서 응답변수 Y 벡터는

$$y\sim (X\beta, \sigma^2I)$$

라고 표현할 수 있다. 이렇듯 $$Var(Y)=Var(\epsilon)=\sigma^2I$$가 성립하는, 즉 오차항끼리 독립이며 등분산이고, 기댓값이 0인 선형 모델을 <strong class="r">Gauss-Markov Model</strong>이라 한다. 이때 기본적으로 y의 분포는 모르므로 분포를 특정하지 않은 채 평균과 분산만을 표기한다.

#### Normal theroy Gauss-Markov model

만약 y벡터가 정규분포를 따른다면, 즉

$$y\sim N(X\beta, \sigma^2I)$$

이라면 이를 <strong class="r">Normal theory Gauss-Markov Model</strong>이라고 한다. 여기서 헷갈리기 쉬운 부분이, 오차항이 정규를 따른다고 가우스-마르코프 모델이 정규성을 띠는 것이 아니라, 모델이 정규성을 띨 때 비로소 오차항이 정규성을 띠게 된다는 것이다. 역명제에 주의하자.

이 정규 모델에서 y 벡터의 원소끼리도 iid인 정규분포를 따르게 된다. 이 모델은 특히 신뢰 구간이나 가설 검정의 면에서 유용하다. 근데 그래서 왜 이 가우스-마르코프 모델을 소개했느냐?

### Contrast Matrix(대조 행렬)

가우스-마르코프 모델의 회귀계수 벡터 beta에 주목하자. 이제부터 행렬 내부의 원소 합이 0인 행렬을 하나 도입할 건데, 이름은 <strong class="r">대조 행렬(contrast matrix)</strong>이라고 한다. 이걸 어디다가 쓰느냐.

각 모델에서의 특성치(평균이나 그룹 간 차이)가 유의미하게 다른지를 검정하는 데에 쓰인다. 예제 1번을 보면 다섯 개의 이삭의 중량이 모두 iid인 정규분포를 따른다고 할 때, 모평균 mu가 0인지 아닌지를 검정하는 one-sample 예제이다. 이때 대조행렬은 C=[1], 즉 스칼라이다.

다음 장의 예제 2번은 8개의 실험체를 두 개의 집단으로 나누어 두 집단 간의 평균이 다른지를 보는 것이다. 여기서 우리가 보고 싶은 것은 베타, 즉 mu1과 mu2의 차이가 있느냐 없느냐에 대한 것이다. 따라서 대조 행렬은

$$C\beta=[1\:-1][\mu_1\;\mu_2]^T=\mu_1-\mu_2=0$$

와 같이 Cb=0과 같은 형태로 사용된다. 이 경우 beta hat과 se(beta hat)을 구할 수 있으므로, 이걸로 Cb와 se(Cb)를 구하여 t검정을 할 수 있다.

예제 3번은 온도와 시간에 따른 생산량에 대한 모델에서 각 온도와 생산량이 유의미한 요인인지를 분석하는 것이다. 즉

$$C\beta=[0\;1\;0][\beta_0\;\beta_1\;\beta_2]^T=[\beta_1]=0$$

$$C\beta=[0\;0\;1][\beta_0\;\beta_1\;\beta_2]^T=[\beta_2]=0$$

과 같이 사용된다.

가장 복잡한 예제 4번을 보자. 여기 중반부터는 나도 이해를 못했다. 알아서 읽어보라고 하고 넘어가셨기 때문. 일단 이해가 된 부분까지만 설명한다.

8마리의 돼지를 각 식단과 접종 방식에 따라 4개의 사육법으로 키운다. 즉 사육법 한 개당 두 마리씩 배정되는 것이다. 이때 모델 1번은 8마리의 돼지가 같은 모평균을 공유, 즉 식단과 접종 방식에 따른 돼지의 차이가 없다는 것을 가정한 모델이다.

2번 모델은 접종만이 영향을 준다고 가정한 모델, 3번 모델은 식단과 접종이 모두 유의미하나, 둘 간의 상호작용(혹은 교호작용)이 없다고 가정한 모델이 된다. 뭐 여기까진 해석이 어렵지 않다.

이제 가장 중요한 4번 모델, 즉 식단과 접종 및 둘의 교호작용까지 모델에 포함시킨 것을 보자. 저 교호작용 항인 감마ij로 인해 사실상 모든 케이스에서의 평균이 다르게 된다. 따라서 감마ij를 모평균 mu와 합쳐서 그냥 mu_ij라고 표현한다면 아래와 같이 된다.

이제 이 각 케이스를 설계 행렬로 표현하면 정말 야무지게 1과 0으로 혼재된 행렬 X가 등장한다. 찬찬히 읽어보면 각 돼지의 순서에 맞게 설계가 되어 있다. 이후 대조 행렬 C를 조정하며 각 모델에서의 가설을 검정하게 된다. 여기부턴 나도 풀이가 납득이 안되므로 나중에 정리가 되면 수정해놓겠다! <strong class="r">Q!</strong>

### Ordinal Categorical Predictors(Less Important)

이제 교수님이 별로 안 중요하다고 말씀하신 9장 내용을 다루겠다. 시험에 안 내신다는 의미로 해석된다. 그래도 혹시 모르니 일단 살펴는 보자.

기존에는 한 범주형 변수의 c개의 클래스를 설명하기 위해 c-1개의 각기 다른 변수를 설정해야했다. 이 때문에 모델도 복잡해지고, 자유도도 감소하는 등 여러 문제가 있었다. 그런데 이 범주형 변수를 하나로 묶을 수 있다면 어떨까?

범주형 변수는 실제 각 클래스의 위계나 순서 및 크기를 고려하지 않았다. 하지만 실제로 이 범주형 변수가 순서를 띤다면? 오히려 고려하는 것이 더 모델 설계에 적합할 것이다. 이런 방식을 ordinal categorical predictors, 혹은 간단하게 <strong class="r">순서형 변수(Ordinal Predictors)</strong>라 한다.

범주형 변수를 도입한 이유는 범주형을 수치형으로 해석할 경우 1, 2, 3과 같이 했을 때 오차가 컸기 때문이 아니냐고? 그렇다면 1, 2.5, 3등으로 해석하면 되잖아? 이게 순서형 변수의 매직이다. 문제는 이게 1, 3, 4일지 2, 3, 4일지 아무도 모른다는 것. 즉 실험자의 가정이 지나치게 들어가므로, 교수님이 좋아하시는 방식은 아니라고.

순서형 모델은 더미 변수가 적고 자유도가 높기에 모델로서 적합하다. 다만 가정에 따라 swing이 크다. 반면 기존의 범주형 모델은 변수가 많고 자유도가 적어 표준오차도 크고 덜 정확해진다.

한편 순서형 변수는 범주형을 수치형으로(categorical->numeric) 고려한 것이기에 사실 범주형 모델의 nested model이다. 즉 범주형 모델에 Full Model이라면, 순서형 모델은 Reduced Model인 것이다! 기존에 다뤘듯이 일반적으로 통계적으로 유의미하다면, FM이 RM보다 정확하다. <strong class="r">Q! 직전엔 순서형이 좋다 해놓고 여기선 범주형이 좋다고? 누구 말이 맞지?</strong>

#### Interactions btw Ordinal and Numerical

캬 여기서도 상호작용이 나온다. 기가 막힌다 정말

일례로 다이아몬드 데이터셋(I1(worst), SI2, SI1, ..., VVS1, IF(best))을 보자. IF와 I1을 제외한 나머지 6개 클래스의 기울기는 별 차이가 없어 모델을 하나로 묶을 수 있다. 즉 3개의 기울기만이 유효한데, 일단 8개를 모두 다 사용한다고 가정하면

기존의 범주형 모델 해석으로는 default로 주어지는 I1의 기울기와, 각 클래스가 기울기와 상호작용하는 추가 항이 붙어서, 기울기가 클래스마다 조금씩 달랐다. 그러나 순서형 모델에서는 변수를 하나만 주고 I1는 0, SI2는 4, SI1는 5.5, IF는 11을 부여하는 등의 방식으로 다르게 줄 수 있다 <strong class="r">Q! 사실 여기 잘 모르겠음</strong>


출처: 회귀분석(STAT342) ㅊㅅㅂ 교수님
