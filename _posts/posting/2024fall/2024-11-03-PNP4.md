---
layout: single
title: "[확률 및 랜덤 과정 9주차] 확률변수 변환(Reparameterization)"
categories: Probability
tag: [MATH, COSE382]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    th, td {
        text-align: center;
    }
    .r {
        color: red;
    }
</style>

아쉽게도 확랜 중간고사는 85점이 나왔다. 원래 90점은 넘을 줄 알았는데, 2-c와 d를 모두 틀려서 15점 감점. 2-d는 힌트를 곧이곧대로 믿었다가 완전히 틀린 계산을 해버렸다.. 앞으로 맥락에 맞게 힌트를 사용할 것! 그래도 잘했다!

## Oct 28 (Mon)

수업의 반 정도는 문제 해설과 교수님의 지론 설파("역시 출석을 안 부르는 게 맞다. 오늘도 출석하지 않은 학생이 100점을 맞았으니", "수학을 못하는 컴퓨터 전공자는 필요가 없다. 그런 코더들은 10년 대로 모두 대체될 것. 수학을 잘해야 경쟁력이 있다" 등).

### 확률 변수 X를 Y로 바꾸어 해석하기

사실 이 파트는 후술할 변수 변환을 위한 초석에 불과하다. 크게 중요한 내용은 없는 듯

일단 확률변수 X가 어떤 함수 g를 통과하여 확률변수 Y가 된다면, Y의 pdf는 직접 구할 수 없다. 이 경우 Y의 cdf를 구한 뒤 y로 편미분함으로써 y의 pdf를 구한다. X와 Y를 인자로 받는 함수 g를 통과한 Z의 pdf도 마찬가지다. Z의 cdf를 구하고, z로 편미분하여 pdf로 변환한다.

이와 같은 방식으로 표준정규분포의 제곱인 확률변수는 자유도가 1인 카이제곱분포(Chi-Square Distribution)를 따름을 보일 수 있다. 확률 변수끼리의 합이나 독립을 가정한 최대, 독립을 가정한 최소 확률변수의 pdf도 구할 수 있다.

이에 따르면 모수를 lambda_i로 갖는 서로 독립인 n개의 지수분포 확률변수 X_i의 최솟값을 X라 하면, X는 시그마 람다(summation of lambdas)의 지수분포를 따른다.

왜냐? 지수분포의 람다는 단위시간 당 사건 발생의 횟수를, 확률변수는 최초 발생까지의 시간을 의미한다는 점을 생각하자. 각각의 독립사건이 확률변수당 lambda_i씩 발생한다면, 총 발생 횟수는 sigma lambda_i가 될 것이고, 그 최솟값을 나타내는 r.v.는 합산된 발생 빈도에서 최초 발생하는 것이기 때문이다. 얘만 수식으로 표기하자면

$$\text{mutually independent }X_i\sim \text{Expo}(\lambda_i),$$

$$X=\text{min}(X_1,\cdots,X_n)\sim \text{Expo}(\sum_i\lambda_i=\lambda_1+\cdots+\lambda_n)$$

## Oct 30 (Wed)

### 확률변수 변환(Change of variables)

위에서 계속 보았듯 어떠한 확률변수를 invertible(역함수가 존재 = 일대일대응 = strictly in/decreasing)하고 differentiable한 함수 g에 통과시킨 것이 Y라면, Y의 pdf는 X의 pdf를 통해 구할 수 있다. 이를 변수 변환이라고 한다. 혹은 Reparameterization이라고도 한다.

변수 변환은 CDF를 편미분하여 PDF를 구하는 방식으로 이루어지는데, 이 과정에서 변수 변환에 따른 미분항이 등장한다. 이 미분항은 rescaling 과정에 대해 적분 시 1이 되도록 보장하기 위한 미소 조정의 역할도 수행한다.

$$f_Y(y)=f_X(x)\left| \frac{dx}{dy} \right|$$

이때 dx/dy라는 것에 주의하자. 흔히 알던 디와이디엑스가 아니다. 이 미분항은 symbolic할 뿐만 아니라 실제 계산과도 같아, 기존의 dy/dx를 역수 취해준 것과 정확히 같은 값이 된다. 따라서 계산 가능한 방향으로 구하여 적용시키면 되겠다.

또한 절댓값이 붙어서 항상 양수(0일 수도 없음. strict하기 때문)로 곱해지는데, 그 이유는 g가 강한 단조증가이든 강한 단조감소이든 결국 양수가 되기 때문이다. 이는 증명 과정을 참조. 위의 방식으로 로그-정규 함수나 아핀(Affine) 변환 등을 보일 수 있다.

### 야코비안 행렬

한편 확률변수를 벡터로 둘 경우 다변수 함수 g를 적용하게 되는데, 이때의 미분항을 <strong class="r">야코비안 행렬(Jacobain Matrix)</strong>이라고 부른다.

$$f_\textbf{Y}(\textbf{y})=f_\textbf{X}(\textbf{x})\left| det(\frac{\partial \textbf{x}}{\partial \textbf{y}}) \right|$$

확률변수 벡터의 경우에는 joint pdf를 구하는 과정에서 행렬식(determinant)의 절댓값을 곱하게 된다. 표기법에 주의.

이때 야코비안 행렬식은 0이 될 수 없다. 역함수가 존재하려면 고윳값이 0이면 안되는데, 야코비안 행렬은 대각분해에서 고윳값만을 가지는 대각행렬이므로, 행렬식이 0일 경우 고윳값 중 0이 발생했다는 의미가 되기 때문이다.

#### Box-Muller

이 야코비안 행렬을 적용한 변수 변환을 통해 쉽게 표준정규분포를 유도할 수 있다. 이를 (Jacobian Matrix) <strong class="r">박스-뮐러 방법(Box-Muller method)</strong>이라고 한다.

루트 2T는 반지름을, U는 각도로 바뀌어 직교좌표 U와 T는 극좌표 X와 Y로 변환되어 원 위에 있게 된다. 자세한 수식은 필기를 읽어보자.

이때 야코비안 행렬식의 절댓값이 1이 나오므로, X와 Y의 joint pdf는 결국 서로 독립인 U와 T의 pdf의 곱으로 표현된다. 그런데 이 곱에서 피타고라스 정리에 의해 t가 (x^2+y^2)/2로 바뀌면서 iid인 표준정규분포를 따르는 두 확률변수 X와 Y가 만들어진다.

이는 컴퓨터가 정규분포를 구현하는 방식이다. 정규분포의 역함수가 존재하지 않기 때문에 Universality of Uniform를 적용할 수 없는데, 이 한계를 뛰어넘은 구현 방식이다. 덕분에 컴퓨터는 정확한 가우시안 분포 값을 쉽게 계산할 수 있게 되었다!


출처: 확률및랜덤과정(COSE382) ㅈㅇㅈ 교수님
