---
layout: single
title: "[컴퓨터 구조 3] 물리/논리주소와 캐시(Cache)메모리"
categories: ComputerArchitecture
tag: [CS, CA]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---

이번 6장에선 RAM(Random Access Memory)에 대해 다룬다. RAM은 ROM(Read Only Memory)과 다르게 휘발성(volatile)이라 전원을 끄면 저장된 내용이 날라가는 특징이 있다.

## Physical / Logical Address

컴퓨터가 사용하는 주소는 '물리 주소(Physical Address)'와 '논리 주소(Logical Address)'가 있는데, 물리 주소는 실제 하드웨어에 저장된 찐 주소이고,
논리 주소는 실행 중인 프로그램 각각에게 0부터 부여된 주소를 말한다.

따라서 프로그램 간에 논리 주소는 겹칠 수 있지만 물리 주소는 겹칠 수 없다는 것! 이때 CPU는 자신이 발생시킨 논리 주소만 알 뿐, 실제 프로그램이 저장되어 있는 물리 주소에 대해서는 알지 못하는데

이 논리 주소와 물리 주소 간의 변환을 담당하는 하드웨어가 '메모리 관리 장치(MMU; Memory Management Unit)'이다.

### 메모리 관리 장치(MMU)의 역할

<img src="https://s3-ap-northeast-2.amazonaws.com/opentutorials-user-file/module/2974/6522.PNG">

아주 간단하게 MMU의 절차를 표현한 도식이다. 순서대로 짚어보면

<div class="notice--success">
<h4>Memory Management Unit</h4>
<ol>
<li>CPU로부터 논리 주소를 받아온다</li>
<li>논리 주소를 (이전 포스팅에서 살펴봤던) 베이스 레지스터(base register)의 값과 더한다. 
<br>베이스 레지스터는 프로그램의 제일 처음의 물리 주소(= 기준 주소; base address)를 저장하고 있다</li>
<li>이 더한 값이 베이스 레지스터와 한계 레지스터(limit register)의 값을 더한 것보다 작아야 한다.<br>즉 가능한 물리 주소 범위는 '베이스 <= 논리 + 베이스 < 논리 + 한계' 이다.
<br>이때 한계 레지스터는 사용 가능한 논리 주소의 최대 크기를 저장한다.</li>
<li>범위를 초과할 시 MMU는 '주소 공간 침범'을 이유로 인터랩트(트랩)을 발생시켜 실행을 중단하고, 그렇지 않다면 메모리의 물리 주소로 향한다</li>
</ol></div>

## Cache Memory

### 메모리 계층 구조(Memory Hierarchy)

메모리는 피라미드 형태로 나타낼 수 있는데, 두 가지 특징이 있다.

첫째. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.

둘째. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.

보통 레지스터 > RAM > 보조 기억 장치 순으로 나타내는데, 이 경우 CPU가 값을 참조하기 위해선 레지스터에 계산된 값이 아니라면 전부 RAM에 가서 값을 읽어와야 한다.

하지만 CPU가 레지스터에 접근하는 속도가 메모리에 접근하는 속도보다 월등히 빠르므로, CPU는 계산을 하고 싶어도 값이 도착하지 못해 fetch하는 데에만 시간을 다 날리는 일이 발생한다.

이걸 해결하기 위해 도입된 것이 캐시(Cache)이다!

<img src="https://media.geeksforgeeks.org/wp-content/uploads/20230609020524/Memory-Hierarchy-Design-768.png">

캐시 메모리는 RAM 중 DRAM(동적 렘. 시간이 지나면 데이터가 사라져 일정 주기로 재활성화해야함)이 아닌 SRAM(정적 렘. 시간이 지나도 데이터가 안 사라짐. 물론 RAM이라 전원을 끄면 사라짐)을 사용한다.

계층 구조에 따라 캐시는 레지스터보다 용량이 크고 DRAM 메모리보다 빠르다. 캐시가 있으면 굳이 대형 마트까지 가서 장 볼 필요 없이, 동네 편의점에서 물품을 사오면 되는 그런 간편한 상황이 가능해진다.

코어(CPU)에 가까운 순서대로 L1, L2, L3 이렇게 명명하며, 명령어와 데이터를 저장하는 캐시를 각각 L1I와 L1D 등으로 구분한 경우 분리형 캐시(split cache)라 부른다.

### 참조 지역성 원리(Locality of reference, Principle of locality)

즉 캐시는 자주 사용되는 값을 미리 갖고 있어야 효과적으로 쓰일 수 있는데, CPU에서 호출한 값을 캐시가 지니고 있는 경우를 캐시 히트(cache hit), 없는 경우를 캐시 미스(cache miss)라 한다.
이를 토대로 캐시 적중률(cache hit ratio)을 계산하는데, 

예상 가능하듯이 hit / (hit + miss)로 계산한다. 일반적인 컴퓨터는 적중률이 85~95% 이상(꽤 높다)!!

그런데 어떻게 사용될 값을 알고 데이터를 갖고 있냐고? 이게 참조 지역성의 원리이다. 크게 두 가지로 설명되는데,

<div class="notice--danger">
<h4>Principle of locality</h4>
<ol>
<li>시간 지역성(temporal locality): CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.</li>
<li>공간 지역성(spartial locality): CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.</li>
</ol></div>

![DM Cache]({{site.url}}/images/2024-03-25-ca3/mapped_cache.png)

베를린 공대 교수님(@ Prof. Dr. Ben H. Juurlink)의 설명에 따르면 다음과 같이 이뤄진다. 편의상 offset은 제외하고 설명

<div class="notice--success">
<h4>Direct-Mapped Cache</h4>
<ol>
<li>물리 주소(2진수)의 일부(이 경우 10자리)를 캐시 인덱스로 설정하고, 캐시 블록의 해당 인덱스에 나머지 값들(태그)을 넣어 둔다.</li>
<li>MMU로부터 물리 주소가 전달되면, 같은 방식으로 인덱스를 대조하여 캐시로 찾아 들어간다.</li>
<li>저장된 태그 값이 전달된 물리 주소의 태그 값과 같으면 히트, 아니면 미스로 판단한다.</li>
<li>히트이면 해당 인덱스의 값을 전달하고, 미스면 다시 메모리(DRAM)로 찾으러 들어간다.</li>
</ol></div>

자세한 내용은 교수님 강의를 직접 들으면서 이해해보자!

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/l0f39oid9DM?si=kqOOc6M69ZnTgmyo&amp;start=254" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</p>


