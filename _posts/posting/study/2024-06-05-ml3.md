---
layout: single
title: "[Deep Learning 3] 미니배치 학습과 SGD(MNIST 활용)"
categories: DeepLearning
tag: [DL]
toc: true # table of contents
author_profile: false # 각 콘텐츠에서 프로필 여부
sidebar: # 사이드바 설정
    nav: "docs"
search: true # 검색 여부 설정
---
<head>
    <!-- Latex -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<style>
    .r {
        color: red;
    }
</style>

## 포스팅에 앞서..

과외하랴 인터벌하랴 바빠서 딥러닝 공부를 쉬엄쉬엄하고 있다. 가뜩이나 이 책은 도서관 대출에 1주 연장까지해서 총 3주 안에 끝마쳐야하는데, 그게 당장 다음주 금요일.. 일주일 남았다.

핑계이고 투정이긴한데, DS를 내가 할 수 있을까..하는 생각이 든다. 언제나 후회막심이지만 이거 빼고는 마땅히 하고 싶은 일도 없어서..

이번 포스팅부터는 수식과 코드가 상당히 많아진다. 아마 '예상 읽는 시간'은 10분 이상으로 jekyll에 표출되지 않을까..

그래서 수식을 <a href="https://latex.codecogs.com/eqneditor/editor.php"><strong>LaTeX</strong>를 통해 작성</a>해보려고 한다. 다만 수식이 너무 많아지면 나중에 포스팅을 읽을 때 뭐가 중요하고, 뭐가 곁다리인지 알기 어려워지니까

메인 내용(주 stream)이 아닌 참고자료 및 이론(서브 stream)에 대한 내용은 <strong>(*) 표시</strong>를 해서 읽을 수 있도록 하겠다. 일단 없는 것부터 읽고, 시간 남으면 *를 읽는 걸로..

LaTeX 표기법에 관하여선 <a href="https://www.overleaf.com/learn/latex/Mathematical_expressions">다양한 글</a>이 있으니 적절히 참고하도록 하자.

또 하나 더. 이 책이 나온지 7년이 넘은 책이다보니, 흔히 쓰이는 python 라이브러리 <strong>tensorflow와 keras</strong>를 사용하지 않는다. 그러다보니 GPU 가동도 안되고 혼파망..

아무래도 다음 책부터는 라이브러리를 활용하는 내용으로 찾아서 읽어야겠다. 이 책은 1~4편까지 있지만 일단 1편만 읽고, 나머지는 나중에 읽는 걸로..

그냥 순수 python 코드로 돌리다보니 시간을 너무 잡아먹고 속도도 지나치게 느리다. 당장 이번 포스팅도 결과가 엉망으로 나오니.. keras를 공부해보도록 하자

## 신경망 학습

사람이 특징(feature)을 추출해 (레이블 유무와는 별개로) 학습 방식을 지정해주는 머신러닝(기계학습)은 사람의 개입이 들어간다.

그러나 우리가 지금 하고 있는 것은 '종단간 기계학습(end-to-end ML)'이라 불리는 딥러닝이 아닌가?

지난 포스팅에서는 하이퍼파라미터를 피클(pkl)에 있는 그대로 불러들여왔지만, 사실 우리가 임의로 지정한 파라미터가 최적의 해가 된다고 판단할 순 없을 것이다.

그렇다면 인간 말고, 데이터 그 자체에서 최적의 파라미터를 찾아가게 할 수는 없을까? 이게 이번 '신경망 학습'의 기본 아이디어다. 신경망이 스스로 학습해나간다는 개념이다.

### 손실 함수

그런데 길을 찾아가려면 일단 지도가 있어야한다. 무일푼으로 아무 것도 없이 머나먼 여행길을 떠날 수는 없는 노릇이다. 

<img src="https://i.pinimg.com/originals/36/24/d3/3624d3b5e6be020de43a0105bda8d577.jpg">

도장깨기를 하고 다니는 포켓몬마스터 지우도 지도를 보고 다니고, 우리의 모험가 도라도 친구 '맵(map)'이 길을 안내하는데, 하물며 딥러닝은 없을까?

인간이 그 지도를 만들기 시작했으니, 이를 손실 함수(<strong class="r">loss function</strong>)라고 한다. 최소화 문제에선 비용 함수(cost function)라고도 하고, 최대화 문제에선 유틸리티 함수(utility function)라고도 하지만, 뭐 난 [로스 펑션]이라고 읽는 게 편하다.

가장 흔히 쓰이는 손실 함수로는 <strong>MSE</strong>(평균 제곱 오차; Mean Squared Error)가 있는데, 수식으로는 다음과 같다.

$$E = \frac{1}{2}\sum_{k}^{} (y_{k}-t_{k})^{2}$$

혹은 (후술할) 최적화까지 나타낸다면

$$\underset{\theta}{min} \frac{1}{N}\sum_{i=1}^{N} \left \| t_{i}-y(x_{i}; \theta) \right \|_{2}^{2}$$

목표로 했던 값(tk)과 출력된 값(yk)간의 차이를 제곱하여 평균을 나눈 식이다. 두 분째 식에 노름(norm)의 오른쪽 위 첨자는 제곱(squared)을, 오른쪽 아래 첨자는 <a href="https://velog.io/@tnsida315/%EA%B0%80%EC%A4%91%EC%B9%98-%EA%B7%9C%EC%A0%9C-L1-L2">L2 규제</a>임을 나타낸다.

코드로도 쉽게 구현이 된다.

```python
import numpy as np

# MSE(Mean Squared Error; 평균 제곱 오차)
def mean_squared_error(y, t):
    return 0.5 * np.sum((y-t)**2)
```

소프트맥스로 도출된 두 결과 y를 보고 원-핫 인코딩된 레이블 t와 비교해서 무엇이 더 적절한 답인지 확인해보자

```python
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # '2'가 정답인 원-핫 인코딩

# 예1: 소프트맥스에서 '2'일 확률이 가장 높다고 나옴
y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0 , 0.1, 0.0, 0.0]
print(mean_squared_error(np.array(y), np.array(t))) # 0.0975, 오차가 작다

# 예2: 소프트맥스에서 '7'일 확률이 가장 높다고 나옴
y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]
print(mean_squared_error(np.array(y), np.array(t))) # 0.5975, 오차가 크다
```

오차가 더 작은 첫번째 예가 적절함을 알 수 있다.

또 다른 손실 함수로 <strong>CEE</strong>(교차 엔트로피 오차; Cross Entropy Error)가 있다.

$$E = -\sum_{k}^{} t_{k}log y_k$$

식을 이해해보면 결국 <strong class="r">정답일 때의 확률값만을 자연로그를 씌운 것</strong>임을 알 수 있다. 레이블 벡터인 t가 원-핫 인코딩이 되어있어 0과 1로만 구성되는데, 정답에 해당하는 값에만 t=1이 곱해진 것이기에 정답일 때의 출력이 전체 값을 정하는 꼴이 되는 것이다. 코드로는 아래와 같다.

```python
# CEE(Cross Entropy Error: 교차 엔트로피 오차)
# 정답 레이블 벡터는 원-핫 인코딩이기 때문에, '추정컨데 정답인 것'의 확률의 자연로그를 취하게 된다.
def cross_entropy_error(y, t):
    delta = 1e-7 # 진수가 0이되지 않게하여 -inf 방지
    return -np.sum(t * np.log(y + delta))
```

### 목적에 따른 손실함수의 종류 (*)

MSE와 CEE를 다룬 이유는 이 둘이 각각 회귀와 분류 문제에서의 양대 손실함수이기 때문이다.

회귀에서는 회귀함수(regression function)와 실측치 간의 차이를 계산해야하기 때문에 MSE를 사용한다. MSE는 이상치(outlier)에 민감하다(이상치가 있으면 계산값이 이상하게 나온다)는 특징이 있긴 하다.

MSE가 L2 노름(유클리드 거리)을 사용하는 반면, L1 노름(멘하탄 거리)을 적용한 MAE(평균절대오차; Mean Absolute Error)도 존재한다. L1 노름답게 식은 제곱 없이 절댓값으로만 이뤄진다.

$$MAE(\theta) = \frac{1}{N}\sum_{i=1}^{N} \left \| t_{i}-y(x_{i}; \theta) \right \|_{1}$$

반대로 분류 문제에서는 CEE가 사용되는데, CEE는 먼저 정보량을 표현하는 방식에서 유래했다.

보통 뉴스 기사는 흔치 않은 일일수록 더 크게 보도된다. 사람들은 확률이 낮은 사건을 더 놀랍게 여긴다. 따라서 정보량의 수식은 확률의 역수에 (값이 너무 커지는 것을 막기 위해) 로그를 취해 표현된다.

$$I(x) = log \frac{1}{p(x)}=-log p(x)$$

이제 엔트로피(entropy)가 나오는데 열역학에서 배우듯이 이것은 불확실성(uncertainty)이나 무작위성(randomness)을 나타내는 말이다. 분산, 즉 확률분포가 클 수록 어떤 사건이 일어날지 예측이 어렵기에, 분산이 클수록 엔트로피도 크다.

엔트로피는 '확률 변수의 정보량의 기댓값'으로 정의되며 수식은

$$H(p) = E_{x \sim p(x)}[-logp(x)]=-\int_{x}^{}p(x)logp(x)dx$$

그래프를 그려보면 p(x)=0과 p(x)=1일 때 엔트로피는 0이 되고, p(x)=0.5일 때 가장 큰 값을 갖는다.

크로스 엔트로피(cross entropy)는 두 확률분포의 유사하지 않은 정도(dissimilarity)를 나타내는데, 어떤 확률분포 q로 확률분포 p를 추정한다고 할 때, 크로스 엔트로피는 q의 정보량을 p에 대한 기댓값을 취하는 것으로 정의된다.

$$H(p,q) = E_{x \sim p(x)}[-logq(x)]=-\int_{x}^{}p(x)logq(x)dx$$

그런데 이 크로스 엔트로피가 CEE로 어떻게 연결되는지가 책에 안 나와있다?! 이건 나중에 시간 남으면 이쪽 파트를 수정해서 보완할테니 일단 넘어가자

### 미니배치 학습

## 최적화




### 편미분과 그래디언트

## 경사 하강법

### 수식을 통한 경사 하강법 설명 (*)

## 확률적 경사 하강법(SGD)




그럼 포스팅을 다시 열심히 작성해보겠다!













<a href="https://knowable.tistory.com/42">퍼셉트론 수렴 정리(perceptron convergence theorem)</a> 설명인데, 중간에 나오는 미분계수 파트는 loss function을 logistic function으로하고, MSE로 계산한 방식이다. Example 1까진 이해했는데 그정도면 내 수준에선 충분하겠지..